{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b00094",
   "metadata": {},
   "source": [
    "### Stats Exercises week 4\n",
    "\n",
    "## Problem 1.\n",
    "\n",
    "(Computer exercise) We will consider a simulation to study null-hypothesis significance testing (NHST).\n",
    "\n",
    "The researchers are using a test with level $\\alpha = 0.05$.\n",
    "\n",
    "In the following cases, compute the expected number of:\n",
    "\n",
    "true positive rejections (TP) where $H_1$ is true and $H_0$ is correctly rejected, \n",
    "\n",
    "false positives (FP) where $H_0$ is true but it is rejected, \n",
    "\n",
    "true negatives (TN) where $H_0$ is true and it is not rejected, \n",
    " \n",
    "and false negatives (FN) $H_1$ is true but $H_0$ is not rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34ee977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 5, 95, 20]\n",
      "Test:\n",
      "\tH_0: 100\tH_1: 100\tpow: 0.8\tpow: 0.05\n",
      "\ttp: 80\t\tfp: 5\t\ttn: 95\t\tfn: 20\n",
      "\n",
      "[20, 5, 95, 80]\n",
      "Test:\n",
      "\tH_0: 100\tH_1: 100\tpow: 0.2\tpow: 0.05\n",
      "\ttp: 20\t\tfp: 5\t\ttn: 95\t\tfn: 80\n",
      "\n",
      "[80, 45, 855, 20]\n",
      "Test:\n",
      "\tH_0: 900\tH_1: 100\tpow: 0.8\tpow: 0.05\n",
      "\ttp: 80\t\tfp: 45\t\ttn: 855\t\tfn: 20\n",
      "\n",
      "[20, 45, 855, 80]\n",
      "Test:\n",
      "\tH_0: 900\tH_1: 100\tpow: 0.2\tpow: 0.05\n",
      "\ttp: 20\t\tfp: 45\t\ttn: 855\t\tfn: 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def meaningful(x, digits = 3):\n",
    "    if x == 0:\n",
    "        return \"0\"\n",
    "    magnitude = math.floor(math.log10(abs(x)))\n",
    "    decimals = digits - magnitude - 1\n",
    "    add = \" \"\n",
    "    if x < 0:\n",
    "        add = \"\"\n",
    "    return add + f\"{round(x, decimals):g}\"\n",
    "\n",
    "def calculate_values(h_0, h_1, alpha, power):\n",
    "    tn = int(round((1 - alpha) * h_0))\n",
    "    fp = int(round(alpha * h_0))\n",
    "    tp = int(round(power * h_1))\n",
    "    fn = int(round((1 - power) * h_1))\n",
    "    assert tn + fp + tp + fn == h_0 + h_1\n",
    "    print([tp, fp, tn, fn])\n",
    "    return f\"Test:\\n\\tH_0: {h_0}\\tH_1: {h_1}\\tpow: {power}\\tpow: {alpha}\\n\\ttp: {tp}\\t\\tfp: {fp}\\t\\ttn: {tn}\\t\\tfn: {fn}\\n\"\n",
    "    \n",
    "\n",
    "print(calculate_values(100,100,0.05,0.8))\n",
    "print(calculate_values(100,100,0.05,0.2))\n",
    "print(calculate_values(900,100,0.05,0.8))\n",
    "print(calculate_values(900,100,0.05,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe8c9f",
   "metadata": {},
   "source": [
    "## Problem 2.\n",
    "\n",
    "A scientific paper in machine learning reports a comparison of three algorithms on a classification task (average accuracy $\\pm$ standard deviation over 8 repeats with an independent random partition of the data; higher is better).\n",
    "\n",
    "| Algorithm    | Accuracy (%) ± standard deviation (%) |\n",
    "|--------------|---------------------------------------|\n",
    "| **Algorithm 1** | 96.0 ± 2.0                           |\n",
    "| Algorithm 2  | 95.0 ± 2.0                           |\n",
    "| Algorithm 3  | 93.5 ± 2.0                           |\n",
    "\n",
    "The authors highlight Algorithm 1 as the most accurate method because it has the highest average accuracy.\n",
    "\n",
    "Let us study this formally by using the Wald test for differences in average accuracies between each pair of algorithms with the null hypothesis that the average accuracies of the two are the same, using \n",
    "$95%$ significance level.\n",
    "\n",
    "Perform the test for differences of all pairs of algorithms. Report the resulting p-values. Consider if authors’ claim of Algorithm 1 being the best can be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18136a46",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Assume that $\\hat \\theta$ is asymptomatically normal\n",
    " \n",
    "\\begin{aligned}\n",
    "\\frac{\\hat \\theta - \\theta_0}{\\hat{se}} & \\rightsquigarrow N(0,1)\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "We test null hypothesis $p_k = p_l$, where $p_i = P(A_i) = Binomial(n,p_i)$ and $l, k\\in 1, 2, 3$\n",
    "\n",
    "We can write $H_0: \\delta = p_k - p_l = 0$\n",
    "\n",
    "The $MLE$ is $\\hat \\delta = \\hat p_l - \\hat p_k$\n",
    "\n",
    "Its standard error is:\n",
    "$$\n",
    "\\hat se = \\sqrt{V(\\hat p_l - \\hat p_k)} = \\sqrt{V(\\hat p_l) + V(\\hat p_k)} = \\sqrt{\\frac{\\sigma_l^2}{n} + \\frac{\\sigma_k^2}{n}}  = \\sqrt{ \\frac{0.02^2}{8} + \\frac{0.02^2}{8} } = 0.01\n",
    "$$\n",
    "\n",
    "The test statistic is:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\hat \\delta - 0}{\\hat se} = \\frac{\\hat p_l - \\hat p_k}{0.01} = 100 \\cdot( \\hat p_l - \\hat p_k)\n",
    "$$\n",
    "\n",
    "For test of size $\\alpha = 0.05$, we reject when $|W|>z_{\\alpha / 2}$\n",
    "\n",
    "The p-value is $p=2\\Phi(-|W|)$\n",
    "\n",
    "Since test set was partitioned independently, we can assume that the test sets were independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "73c5661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing algorith 1 to 2\n",
      "\tW:  1\n",
      "\tp:  0.317\n",
      "\tnull-hypothesis rejected: False\n",
      "Comparing algorith 1 to 3\n",
      "\tW:  2.5\n",
      "\tp:  0.0124\n",
      "\tnull-hypothesis rejected: True\n",
      "Comparing algorith 2 to 3\n",
      "\tW:  1.5\n",
      "\tp:  0.134\n",
      "\tnull-hypothesis rejected: False\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "algorithm_w = lambda x,y: (x - y)*100\n",
    "def calculate_p_value(w):\n",
    "    return 2*norm.cdf(-abs(w))\n",
    "\n",
    "algorithm_means = [0.96, 0.95, 0.935]\n",
    "pairs = [(0,1),(0,2),(1, 2)]\n",
    "for a, b in pairs:\n",
    "    p_1, p_2 = algorithm_means[a], algorithm_means[b]\n",
    "    w = algorithm_w(p_1, p_2)\n",
    "    p_val = calculate_p_value(w)\n",
    "    print(f\"Comparing algorith {a + 1} to {b + 1}\")\n",
    "    print(f\"\\tW: {meaningful(w)}\")\n",
    "    print(f\"\\tp: {meaningful(p_val)}\")\n",
    "    print(f\"\\tnull-hypothesis rejected: {p_val < 0.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbff9bc",
   "metadata": {},
   "source": [
    "## Problem 3.\n",
    "\n",
    "A randomized, double-blind experiment was conducted to assess the effectiveness of several drugs for reducing postoperative nausea. The data are as follows.\n",
    "\n",
    "| Drug                    | Number of Patients | Incidence of Nausea |\n",
    "|-------------------------|-------------------:|--------------------:|\n",
    "| Placebo                 |                 80 |                  45 |\n",
    "| Chlorpromazine          |                 75 |                  26 |\n",
    "| Dimenhydrinate          |                 85 |                  52 |\n",
    "| Pentobarbital (100 mg)  |                 67 |                  35 |\n",
    "| Pentobarbital (150 mg)  |                 85 |                  37 |\n",
    "\n",
    "\n",
    "### 3.1.\n",
    "\n",
    "Test each drug versus the placebo by comparing the rates of incidences of nausea with Wald test. Report the p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a3642",
   "metadata": {},
   "source": [
    "The null hypothesis is that the placebo has the same or better effectiveness than a drug.\n",
    "\n",
    "$$\n",
    "H_0 : \\theta \\leq \\theta_0\n",
    "$$\n",
    "\n",
    "We can write $H_0: \\delta = p_p - p_d \\leq 0$, where p stands for placebo and d for drug. This means that probability of nausea is smaller for placebo than the drug.\n",
    "\n",
    "The $MLE$ is $\\hat \\delta = \\hat p_p - \\hat p_d$\n",
    "\n",
    "Its standard error is:\n",
    "$$\n",
    "\\hat se = \\sqrt{V(\\hat p_p - \\hat p_d)} = \\sqrt{V(\\hat p_p) + V(\\hat p_d)} = \\sqrt{\\frac{\\hat p_p(1- \\hat p_p)}{n} + \\frac{\\hat p_d(1- \\hat p_d)}{m}  }\n",
    "$$\n",
    "\n",
    "The test statistic is:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\hat \\delta - 0}{\\hat se} = \\frac{\\hat p_p - \\hat p_d}{\\sqrt{\\frac{\\hat p_p(1- \\hat p_p)}{n} + \\frac{\\hat p_d(1- \\hat p_d)}{m}  }} \n",
    "$$\n",
    "\n",
    "A $W>0$ value would indicate that\n",
    "\\begin{aligned}\n",
    "\\hat p_p - \\hat p_d &> 0 \\\\\n",
    "\\hat p_p &> \\hat p_d \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "Which is the opposite of the null hypothesis. So we can calculate p-value as:\n",
    "\n",
    "$$\n",
    "\\text{p-value} = P_{\\theta_0}(W > w) \\approx P(Z > w) = 1 - P(Z \\leq w) = 1 - \\phi(w)\n",
    "$$\n",
    "A $W<0$ value would indicate that\n",
    "\\begin{aligned}\n",
    "\\hat p_p - \\hat p_d &< 0 \\\\\n",
    "\\hat p_p &< \\hat p_d \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "Which is the opposite of the null hypothesis. So we can calculate p-value as:\n",
    "\n",
    "$$\n",
    "\\text{p-value} = P_{\\theta_0}(W < w) \\approx P(Z < w) = \\phi(w)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4e8f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug: Chlorpromazine        \tw:  2.76\tp_val:  0.00285\n",
      "Drug: Dimenhydrinate        \tw: -0.643\tp_val:  0.26\n",
      "Drug: Pentobarbital (100 mg)\tw:  0.486\tp_val:  0.313\n",
      "Drug: Pentobarbital (150 mg)\tw:  1.65\tp_val:  0.0498\n"
     ]
    }
   ],
   "source": [
    "def calculate_W(n, m, p_1, p_2):\n",
    "    p_1 = p_1 / n\n",
    "    p_2 = p_2 / m\n",
    "    denom = p_1 - p_2\n",
    "    a = p_1*(1-p_1) / n\n",
    "    b = p_2*(1-p_2) / m\n",
    "    return denom / sqrt(a + b)\n",
    "\n",
    "\n",
    "def calculate_p_value_one_sided(w):\n",
    "    if w >= 0:\n",
    "        return 1 - norm.cdf(w)\n",
    "    return norm.cdf(w)\n",
    "\n",
    "placebo_total = 80\n",
    "placebo_nause = 45\n",
    "\n",
    "drugs = [[75, 26, \"Chlorpromazine        \"], [85, 52, \"Dimenhydrinate        \"], [67, 35, \"Pentobarbital (100 mg)\"], [85, 37, \"Pentobarbital (150 mg)\"]]\n",
    "p_vals = []\n",
    "for drug_total, durg_nausea, name in drugs:\n",
    "    w = calculate_W(placebo_total, drug_total, placebo_nause, durg_nausea)\n",
    "    p = calculate_p_value_one_sided(w)\n",
    "    p_vals.append(p)\n",
    "    print(f\"Drug: {name}\\tw: {meaningful(w)}\\tp_val: {meaningful(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd037c3",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2.\n",
    "Report the estimated odds-ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd55b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds-ratio for Chlorpromazine        :  1.62\t 0.562,  0.347\n",
      "Odds-ratio for Dimenhydrinate        :  0.919\t 0.562,  0.612\n",
      "Odds-ratio for Pentobarbital (100 mg):  1.08\t 0.562,  0.522\n",
      "Odds-ratio for Pentobarbital (150 mg):  1.29\t 0.562,  0.435\n"
     ]
    }
   ],
   "source": [
    "drugs_odds = [\n",
    "    [\"Placebo               \", 80, 45],\n",
    "    [\"Chlorpromazine        \", 75, 26],\n",
    "    [\"Dimenhydrinate        \", 85, 52],\n",
    "    [\"Pentobarbital (100 mg)\", 67, 35],\n",
    "    [\"Pentobarbital (150 mg)\", 85, 37]\n",
    "    ]\n",
    "\n",
    "placebo = 45 / 80\n",
    "for name, drug_total, durg_nausea in drugs_odds[1:]:\n",
    "    print(f\"Odds-ratio for {name}: {meaningful(placebo/(durg_nausea / drug_total))}\\t{meaningful(placebo)}, {meaningful(durg_nausea/drug_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269f209",
   "metadata": {},
   "source": [
    "## Problem 4.\n",
    "\n",
    "Continuing with the same data and setting as in the previous exercise.\n",
    "\n",
    "Use the Bonferroni and the FDR method to adjust for multiple testing. Report the adjusted p-values. Consider how the adjustment affects the conclusions of the test when using 95% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cb867",
   "metadata": {},
   "source": [
    "Since there are four tests, we can simply adjust the p-values by multiplying them by $4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "90201dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonferonni: Chlorpromazine        :\t 0.0114\n",
      "Bonferonni: Dimenhydrinate        :\t 1\n",
      "Bonferonni: Pentobarbital (100 mg):\t 1\n",
      "Bonferonni: Pentobarbital (150 mg):\t 0.199\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f\"Bonferonni: {drugs_odds[i+1][0]}:\\t{meaningful(min([p_vals[i] * 4, 1]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecdf1d",
   "metadata": {},
   "source": [
    "FDR Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e55149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDR: Chlorpromazine        :\t 0.0114\n",
      "FDR: Dimenhydrinate        :\t 0.313\n",
      "FDR: Pentobarbital (100 mg):\t 0.313\n",
      "FDR: Pentobarbital (150 mg):\t 0.0996\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "adjusted = false_discovery_control(p_vals)\n",
    "for i in range(4):\n",
    "    print(f\"FDR: {drugs_odds[i+1][0]}:\\t{meaningful(adjusted[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446602be",
   "metadata": {},
   "source": [
    "## Problem 5.\n",
    "\n",
    "In this exercise, we will compare Bayesian and maximum likelihood estimation for the multinomial distribution.\n",
    "\n",
    "Multinomial distribution is a generalisation of the binomial to $k$ values with vector parameter $p=(p_1,...,p_k),\\sum_{i=1}^k p_i, p_1 \\geq 0, i = 1,...,k$ denoting the probabilities of the different outcomes.\n",
    "\n",
    "Consider $n=20$ throws $X_1,...,X_n$ from an 6-sided die, modelled as 20 draws from a multinomial distribution with unknown $p$. To test the different approaches, we consider a sequence simulated from a fair 6-sided die (the observations are integers between 1 and 6)\n",
    "\n",
    "$(6,3,2,1,6,6,2,6,1,3,3,2,2,2,5,3,1,6,5,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c788a3c",
   "metadata": {},
   "source": [
    "## 5.1.\n",
    "\n",
    "Compute the maximum likelihood estimate of $p, \\hat p_j = \\frac{1}{n}\\sum_{i=1}^n I(X_i = j)$\n",
    "\n",
    "We can get the maximum likelihoods for $p=(\\hat p_1,...,\\hat p_n)$ by calculating the proportions of results in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7800d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_1: 0.2\n",
      "p_2: 0.25\n",
      "p_3: 0.2\n",
      "p_4: 0.0\n",
      "p_5: 0.1\n",
      "p_6: 0.25\n"
     ]
    }
   ],
   "source": [
    "sample = [6,3,2,1,6,6,2,6,1,3,3,2,2,2,5,3,1,6,5,1]\n",
    "probs = {i+1:sample.count(i+1) / len(sample) for i in range(6)}\n",
    "for key, val in probs.items():\n",
    "    print(f\"p_{key}: {val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb70c1",
   "metadata": {},
   "source": [
    "## 5.2\n",
    "\n",
    "Using the $\\hat p$, compute the predictive likelihood (i.e. likelihood of future observations) of observing the following sequence in the future: $(1, 5, 4)$\n",
    "\n",
    "\n",
    "### Answer:\n",
    "\n",
    "If likelihood of future observations is $\\prod_{i=1}^k I(X_i = j)$ and $I(X_3 = 4) = 0$, then the likelihood is also $0$. (Even one 0 term in the product means the whole product is 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c8ebf",
   "metadata": {},
   "source": [
    "## 5.3.\n",
    "\n",
    "\n",
    "For Bayesian inference, we use the conjugate prior $ p \\sim \\text{Dirichlet}(\\alpha) $, where $ \\alpha = (\\alpha_1, \\ldots, \\alpha_k), \\, \\alpha_i > 0, \\, i = 1, \\ldots, k $.\n",
    "\n",
    "We assume that all values are equally likely *a priori* (before seeing the data), which implies $ \\alpha_1 = \\cdots = \\alpha_k $.\n",
    "\n",
    "The Dirichlet distribution is a distribution over probability vectors. Given  \n",
    "$ p \\sim \\text{Dirichlet}(\\alpha) $, the expectation is:  \n",
    "$$\n",
    "\\mathbb{E}(p_i) = \\frac{\\alpha_i}{\\alpha_0}, \\quad \\text{where } \\alpha_0 = \\sum_{j=1}^k \\alpha_j\n",
    "$$  \n",
    "The marginal distribution of $ p_i $ is $ \\text{Beta}(\\alpha_i, \\alpha_0 - \\alpha_i) $.\n",
    "\n",
    "\n",
    "Given an observed sequence $ X_1, \\ldots, X_n $, the posterior of $ p $ is:\n",
    "\n",
    "$$\n",
    "p \\mid X_1, \\ldots, X_n \\sim \\text{Dirichlet}(\\alpha^*)\n",
    "$$\n",
    "\n",
    "with  \n",
    "$$\n",
    "\\alpha^* = (\\alpha_1^*, \\ldots, \\alpha_k^*), \\quad \\alpha_j^* = \\alpha_j + \\sum_{i=1}^n \\mathbf{I}(X_i = j)\n",
    "$$\n",
    "\n",
    "\n",
    "**Compute the posterior distribution** given the following prior distributions:\n",
    "\n",
    "1. $ \\alpha_1 = \\cdots = \\alpha_k = 0.1 $  \n",
    "2. $ \\alpha_1 = \\cdots = \\alpha_k = 1 $  \n",
    "3. $ \\alpha_1 = \\cdots = \\alpha_k = 10 $\n",
    "\n",
    "**What do you observe? What kind of prior should we use in a case where we are unsure if the die is fair or loaded?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c4d3a",
   "metadata": {},
   "source": [
    "### 5.3.1 $ \\alpha_1 = \\cdots = \\alpha_k = 0.1 $  \n",
    "\n",
    "$$\\alpha_j^* = \\alpha_j + \\sum_{i=1}^n \\mathbf{I}(X_i = j)$$\n",
    "\n",
    "$$\\mathbb{E}(p_l) = \\frac{\\alpha_l}{\\alpha_0}, \\quad \\text{where } \\alpha_0 = \\sum_{i=1}^k \\alpha_i$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(p_l^*)= \\frac{\\alpha_j + \\sum_{i=1}^n \\mathbf{I}(X_i = j)}{\\alpha_0}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e52d3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.1\n",
      "\tp_1:  0.199, p_2:  0.248, p_3:  0.199, p_4:  0.00485, p_5:  0.102, p_6:  0.248, \n",
      "a: 1\n",
      "\tp_1:  0.192, p_2:  0.231, p_3:  0.192, p_4:  0.0385, p_5:  0.115, p_6:  0.231, \n",
      "a: 10\n",
      "\tp_1:  0.175, p_2:  0.188, p_3:  0.175, p_4:  0.125, p_5:  0.15, p_6:  0.188, \n"
     ]
    }
   ],
   "source": [
    "counts = {i+1:sample.count(i+1)for i in range(6)}\n",
    "\n",
    "def calculate_posterior(a):\n",
    "    new_alphas = []\n",
    "    for _, value in counts.items():\n",
    "        new_alphas.append(a + value)\n",
    "\n",
    "    adjusted_values = []\n",
    "    for new_a in new_alphas:\n",
    "        adjusted_values.append(new_a / sum(new_alphas) )\n",
    "    info = f\"a: {a}\\n\\t\"\n",
    "    for i in range(1, 7):\n",
    "        info += f\"p_{i}: {meaningful(adjusted_values[i-1], 3)}, \"\n",
    "    print(info)\n",
    "\n",
    "calculate_posterior(0.1)\n",
    "calculate_posterior(1)\n",
    "calculate_posterior(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
