{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Data Science 2025\n",
        "\n",
        "# Week 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this week's exercise, we look at prompting and zero- and few-shot task settings. Below is a text generation example from https://github.com/TurkuNLP/intro-to-nlp/blob/master/text_generation_pipeline_example.ipynb demonstrating how to load a text generation pipeline with a pre-trained model and generate text with a given prompt. Your task is to load a similar pre-trained generative model and assess whether the model succeeds at a set of tasks in zero-shot, one-shot, and two-shot settings.\n",
        "\n",
        "**Note: Downloading and running the pre-trained model locally may take some time. Alternatively, you can open and run this notebook on [Google Colab](https://colab.research.google.com/), as assumed in the following example.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIQ1s96UCcJW"
      },
      "source": [
        "## Text generation example\n",
        "\n",
        "This is a brief example of how to run text generation with a causal language model and `pipeline`.\n",
        "\n",
        "Install [transformers](https://huggingface.co/docs/transformers/index) python package. This will be used to load the model and tokenizer and to run generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4fUBJmXHCHw-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZRNZgRJCt6Q"
      },
      "source": [
        "Import the `AutoTokenizer`, `AutoModelForCausalLM`, and `pipeline` classes. The first two support loading tokenizers and generative models from the [Hugging Face repository](https://huggingface.co/models), and the last wraps a tokenizer and a model for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jwyK005xCFSF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\koodit\\DataScienceMasters\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QJPDe3ZC_sL"
      },
      "source": [
        "Load a generative model and its tokenizer. You can substitute any other generative model name here (e.g. [other TurkuNLP GPT-3 models](https://huggingface.co/models?sort=downloads&search=turkunlp%2Fgpt3)), but note that Colab may have issues running larger models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wqTxn_QaCNjZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\koodit\\DataScienceMasters\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tuoma\\.cache\\huggingface\\hub\\models--TurkuNLP--gpt3-finnish-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'TurkuNLP/gpt3-finnish-large'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ADWWb77e1sY"
      },
      "source": [
        "Instantiate a text generation pipeline using the tokenizer and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IIJzNrEe5qx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\n",
        "    'text-generation',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=model.device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAohNr1ciwaU"
      },
      "source": [
        "We can now call the pipeline with a text prompt; it will take care of tokenizing, encoding, generation, and decoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcOJkiKi5vr",
        "outputId": "11cb09ab-310d-438e-e372-ef8d7f8f66a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Terve, miten menee?”\\n”Hyvin.”\\n”Entä te?”\\n”Oikein hyvin.”\\n”Näytät aika kalpealta.'}]\n"
          ]
        }
      ],
      "source": [
        "output = pipe('Terve, miten menee?', max_new_tokens=25)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNRMsxXOjSo0"
      },
      "source": [
        "Just print the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Op7MJ6XjahG",
        "outputId": "5d9e26dd-3e80-4663-a712-d85093fad073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Terve, miten menee?”\n",
            "”Hyvin.”\n",
            "”Entä te?”\n",
            "”Oikein hyvin.”\n",
            "”Näytät aika kalpealta.\n"
          ]
        }
      ],
      "source": [
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YROp3hyikXPO"
      },
      "source": [
        "We can also call the pipeline with any arguments that the model `generate` function supports. For details on text generation using `transformers`, see e.g. [this tutorial](https://huggingface.co/blog/how-to-generate).\n",
        "\n",
        "Example with sampling and a high `temperature` parameter to generate more chaotic output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22QjXE88jkim",
        "outputId": "372a4fc2-e305-4034-cea3-a52b6103c24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            " Mua vähän ärsyttää tämä asia, koska olen itse herkkä aistimaan ihmisten tunnetiloja ja olen itsekin huomannut, että ihmiset usein kertovat suoraan jos jokin on pielessä. Mutta välillä\n"
          ]
        }
      ],
      "source": [
        "output = pipe(\n",
        "    'Terve, miten menee?',\n",
        "    do_sample=True,\n",
        "    temperature=10.0,\n",
        "    max_new_tokens=25\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1\n",
        "\n",
        "Your task is to assess whether a generative model succeeds in the following tasks in zero-shot, one-shot, and two-shot settings:\n",
        "\n",
        "- binary sentiment classification (positive / negative)\n",
        "\n",
        "- person name recognition\n",
        "\n",
        "- two-digit addition (e.g. 11 + 22 = 33)\n",
        "\n",
        "For example, for assessing whether a generative model can name capital cities, we could use the following prompts:\n",
        "\n",
        "- zero-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "- one-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Sweden?\\\n",
        "\t>Answer: Stockholm\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "- two-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Sweden?\\\n",
        "\t>Answer: Stockholm\n",
        "\t>\n",
        "\t>Question: What is the capital of Denmark?\\\n",
        "\t>Answer: Copenhagen\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "\n",
        "You can do the tasks either in English or Finnish and use a generative model of your choice from the Hugging Face models repository, for example the following models:\n",
        "\n",
        "- English: `gpt2-large`\n",
        "- Finnish: `TurkuNLP/gpt3-finnish-large`\n",
        "\n",
        "You can either come up with your own instructions for the tasks or use the following:\n",
        "\n",
        "- English:\n",
        "\t- binary sentiment classification: \"Do the following texts express a positive or negative sentiment?\"\n",
        "\t- person name recognition: \"List the person names occurring in the following texts.\"\n",
        "\t- two-digit addition: \"This is a first grade math exam.\"\n",
        "- Finnish:\n",
        "\t- binary sentiment classification: \"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\"\n",
        "\t- person name recognition: \"Listaa seuraavissa teksteissä mainitut henkilönnimet.\"\n",
        "\t- two-digit addition: \"Tämä on ensimmäisen luokan matematiikan koe.\"\n",
        "\n",
        "Come up with at least two test cases for each of the three tasks, and come up with your own one- and two-shot examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-shot 1. example.\n",
            "\tShould be: Positiivinen\n",
            "\n",
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            "Teksti: Tämä on todella hyvä elokuva!\n",
            "Vastaus: Kyllä, tämä on todella\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Sentiment Classification\n",
        "\n",
        "def get_evaluation(prompt, shot, ind, answer, should, tokens=5):\n",
        "    print(f\"{shot}-shot {ind}. example.\\n\\tShould be: {should}\\n\")\n",
        "    generated = pipe(prompt, max_new_tokens=tokens)[0][\"generated_text\"]\n",
        "    print(generated)\n",
        "    print(\"-\" * 20 + \"\\n\")\n",
        "\n",
        "# Zero-shot:\n",
        "\n",
        "prompt = \"\"\"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
        "Teksti: Tämä on todella hyvä elokuva!\n",
        "Vastaus:\"\"\"\n",
        "get_evaluation(prompt, \"Zero\", 1, \"Vastaus: \", \"Positiivinen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Submit this exercise by submitting your code and your answers to the above questions as comments on the MOOC platform. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot 1. example.\n",
            "\tShould be: Negatiivinen\n",
            "\n",
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            "Teksti: Tämä on todella hyvä elokuva!\n",
            "Vastaus: Positiivinen\n",
            "\n",
            "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
            "Vastaus: Kahvin juominen iltapäivällä ei häiritse\n",
            "--------------------\n",
            "\n",
            "One-shot 2. example.\n",
            "\tShould be: Negatiivinen\n",
            "\n",
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            "Teksti: Minusta kermakakut mansikoilla ovat aivan parhaita.\n",
            "Vastaus: Positiivinen\n",
            "\n",
            "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
            "Vastaus: Ei haittaa, sillä illalla\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# One shot:\n",
        "\n",
        "prompt = \"\"\"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
        "Teksti: Tämä on todella hyvä elokuva!\n",
        "Vastaus: Positiivinen\n",
        "\n",
        "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
        "Vastaus:\"\"\"\n",
        "get_evaluation(prompt, \"One\", 1, \"Vastaus: \", \"Negatiivinen\")\n",
        "prompt = \"\"\"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
        "Teksti: Minusta kermakakut mansikoilla ovat aivan parhaita.\n",
        "Vastaus: Positiivinen\n",
        "\n",
        "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
        "Vastaus:\"\"\"\n",
        "get_evaluation(prompt, \"One\", 2, \"Vastaus: \", \"Negatiivinen\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Two-shot 1. example.\n",
            "\tShould be: Positiivinen\n",
            "\n",
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            "Teksti: Tämä on todella hyvä elokuva!\n",
            "Vastaus: Positiivinen\n",
            "\n",
            "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
            "Vastaus: Negatiivinen\n",
            "\n",
            "Teksti: Haluan aina syödä tivolissa hattaraa, se on makeaa ja sulaa suuhun.\n",
            "Vastaus: Negatiivinen\n",
            "\n",
            "Teksti: Haluan\n",
            "--------------------\n",
            "\n",
            "Two-shot 2. example.\n",
            "\tShould be: Negatiivinen\n",
            "\n",
            "Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
            "Teksti: Minusta kermakakut mansikoilla ovat aivan parhaita.\n",
            "Vastaus: Positiivinen\n",
            "\n",
            "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
            "Vastaus: Negatiivinen\n",
            "\n",
            "Teksti: Saisi jo tulla kesä, alkaa käymään hermoille nämä loskakelit\n",
            "Vastaus: Negatiivinen\n",
            "\n",
            "Teksti: Haluan\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Two-shot:\n",
        "\n",
        "prompt = \"\"\"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
        "Teksti: Tämä on todella hyvä elokuva!\n",
        "Vastaus: Positiivinen\n",
        "\n",
        "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
        "Vastaus: Negatiivinen\n",
        "\n",
        "Teksti: Haluan aina syödä tivolissa hattaraa, se on makeaa ja sulaa suuhun.\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"Two\", 1, \"Vastaus: \", \"Positiivinen\")\n",
        "\n",
        "prompt = \"\"\"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\n",
        "Teksti: Minusta kermakakut mansikoilla ovat aivan parhaita.\n",
        "Vastaus: Positiivinen\n",
        "\n",
        "Teksti: En nauti kahvin juomisesta iltapäivällä, se häiritsee yöunia.\n",
        "Vastaus: Negatiivinen\n",
        "\n",
        "Teksti: Saisi jo tulla kesä, alkaa käymään hermoille nämä loskakelit\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"Two\", 2, \"Vastaus: \", \"Negatiivinen\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-shot 1. example.\n",
            "\tShould be: Toni, Joonas ja Maija\n",
            "\n",
            "Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
            "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
            "Vastaus:\n",
            "Oikein sopiva nimi!\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Name recognition\n",
        "\n",
        "# Zero-shot\n",
        "\n",
        "prompt = \"\"\"Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
        "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"Zero\", 1, \"Vastaus: \", \"Toni, Joonas ja Maija\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot 1. example.\n",
            "\tShould be: Tuomas ja Antti\n",
            "\n",
            "Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
            "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
            "Vastaus:Toni, Joonas ja Maija\n",
            "\n",
            "Teksti: Apostoli Tuomaksen ensimmäinen tehtävä oli muistuttaa muita heidän kärsimättömyydestään, varsinkin Anttia\n",
            "Vastaus:Apostoli Tuomaksen tehtävä\n",
            "--------------------\n",
            "\n",
            "One-shot 2. example.\n",
            "\tShould be: Kauko ja Pirkko\n",
            "\n",
            "Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
            "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
            "Vastaus: Toni, Joonas ja Maija\n",
            "\n",
            "Teksti: Tapasin isovanhempani ensimmäistä kertaa kymmenen vuotiaana. Kauko papasta ja Pirkko mummosta tuli minulle välittömästi läheisiä ihmisiä.\n",
            "Vastaus: Muistan kun mummoni kertoi minulle\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# One-shot:\n",
        "\n",
        "prompt = \"\"\"Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
        "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
        "Vastaus:Toni, Joonas ja Maija\n",
        "\n",
        "Teksti: Apostoli Tuomaksen ensimmäinen tehtävä oli muistuttaa muita heidän kärsimättömyydestään, varsinkin Anttia\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"One\", 1, \"Vastaus: \", \"Tuomas ja Antti\")\n",
        "\n",
        "prompt = \"\"\"Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
        "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
        "Vastaus: Toni, Joonas ja Maija\n",
        "\n",
        "Teksti: Tapasin isovanhempani ensimmäistä kertaa kymmenen vuotiaana. Kauko papasta ja Pirkko mummosta tuli minulle välittömästi läheisiä ihmisiä.\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"One\", 2, \"Vastaus: \", \"Kauko ja Pirkko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Two-shot 1. example.\n",
            "\tShould be: Jesse, Kimmo ja Heikki\n",
            "\n",
            "Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
            "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
            "Vastaus:Toni, Joonas ja Maija\n",
            "\n",
            "Teksti: Apostoli Tuomaksen ensimmäinen tehtävä oli muistuttaa muita heidän kärsimättömyydestään, varsinkin Anttia\n",
            "Vastaus: Tuomas ja Antti\n",
            "\n",
            "Teksti: Harkitsimme pitkään uudelle koiraa annettavaa nimeä. Siskoni ehdotti Jesseä, minä Kimmoa ja äitimme Heikkiä\n",
            "Vastaus: Jesse\n",
            "\n",
            "Teksti: Hän oli\n",
            "--------------------\n",
            "\n",
            "Two-shot 2. example.\n",
            "\tShould be: Martti ja Sauli\n",
            "\n",
            "Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
            "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
            "Vastaus: Toni, Joonas ja Maija\n",
            "\n",
            "Teksti: Tapasin isovanhempani ensimmäistä kertaa kymmenen vuotiaana. Kauko papasta ja Pirkko mummosta tuli minulle välittömästi läheisiä ihmisiä.\n",
            "Vastaus: Kauko ja Pirkko\n",
            "\n",
            "Teksti: Martti tuli maailmalla tunnetuksi diplomaatin taidoistaan, toisin kuin Sauli, joka tunnettiin kansanedustajana.\n",
            "Vastaus: Sauli\n",
            "\n",
            "Teksti: Martti oli\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Two-shot:\n",
        "\n",
        "prompt = \"\"\"Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
        "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
        "Vastaus:Toni, Joonas ja Maija\n",
        "\n",
        "Teksti: Apostoli Tuomaksen ensimmäinen tehtävä oli muistuttaa muita heidän kärsimättömyydestään, varsinkin Anttia\n",
        "Vastaus: Tuomas ja Antti\n",
        "\n",
        "Teksti: Harkitsimme pitkään uudelle koiraa annettavaa nimeä. Siskoni ehdotti Jesseä, minä Kimmoa ja äitimme Heikkiä\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"Two\", 1, \"Vastaus: \", \"Jesse, Kimmo ja Heikki\")\n",
        "\n",
        "prompt = \"\"\"Listaa seuraavissa teksteissä mainitut henkilönnimet.\n",
        "Teksti: Toni ja Joonas kävivät tänään Maijalla kylässä\n",
        "Vastaus: Toni, Joonas ja Maija\n",
        "\n",
        "Teksti: Tapasin isovanhempani ensimmäistä kertaa kymmenen vuotiaana. Kauko papasta ja Pirkko mummosta tuli minulle välittömästi läheisiä ihmisiä.\n",
        "Vastaus: Kauko ja Pirkko\n",
        "\n",
        "Teksti: Martti tuli maailmalla tunnetuksi diplomaatin taidoistaan, toisin kuin Sauli, joka tunnettiin kansanedustajana.\n",
        "Vastaus:\"\"\"\n",
        "\n",
        "get_evaluation(prompt, \"Two\", 2, \"Vastaus: \", \"Martti ja Sauli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-shot 1. example.\n",
            "\tShould be: 7\n",
            "\n",
            "Tämä on ensimmäisen luokan matematiikan koe\n",
            "Kysymys: 3 + 4\n",
            "Vastaus: =5\n",
            "\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Additive operation\n",
        "\n",
        "# Zero-shot\n",
        "\n",
        "prompt = \"\"\"Tämä on ensimmäisen luokan matematiikan koe\n",
        "Kysymys: 3 + 4\n",
        "Vastaus: \"\"\"\n",
        "get_evaluation(prompt, \"Zero\", 1, \"Vastaus: \", \"7\", 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot 1. example.\n",
            "\tShould be: 14\n",
            "\n",
            "Tämä on ensimmäisen luokan matematiikan koe\n",
            "Kysymys: 3 + 4\n",
            "Vastaus: 7\n",
            "\n",
            "Kysymys: 2 + 12\n",
            "Vastaus: .....\n",
            "--------------------\n",
            "\n",
            "One-shot 2. example.\n",
            "\tShould be: 2\n",
            "\n",
            "Tämä on ensimmäisen luokan matematiikan koe\n",
            "Kysymys: 5 + 2\n",
            "Vastaus: 7\n",
            "\n",
            "Kysymys: 1 + 1\n",
            "Vastaus: ______\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# One-shot\n",
        "\n",
        "prompt = \"\"\"Tämä on ensimmäisen luokan matematiikan koe\n",
        "Kysymys: 3 + 4\n",
        "Vastaus: 7\n",
        "\n",
        "Kysymys: 2 + 12\n",
        "Vastaus: \"\"\"\n",
        "get_evaluation(prompt, \"One\", 1, \"Vastaus: \", \"14\", 2)\n",
        "\n",
        "prompt = \"\"\"Tämä on ensimmäisen luokan matematiikan koe\n",
        "Kysymys: 5 + 2\n",
        "Vastaus: 7\n",
        "\n",
        "Kysymys: 1 + 1\n",
        "Vastaus: \"\"\"\n",
        "get_evaluation(prompt, \"One\", 2, \"Vastaus: \", \"2\", 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Two-shot 1. example.\n",
            "\tShould be: 3\n",
            "\n",
            "Tämä on ensimmäisen luokan matematiikan koe\n",
            "Kysymys: 3 + 4\n",
            "Vastaus: 7\n",
            "\n",
            "Kysymys: 2 + 12\n",
            "Vastaus: 14\n",
            "\n",
            "Kysymys: 1 + 2\n",
            "Vastaus: _____\n",
            "--------------------\n",
            "\n",
            "Two-shot 1. example.\n",
            "\tShould be: 6\n",
            "\n",
            "Tämä on ensimmäisen luokan matematiikan koe\n",
            "Kysymys: 5 + 2\n",
            "Vastaus: 7\n",
            "\n",
            "Kysymys: 4 + 5\n",
            "Vastaus: 9\n",
            "\n",
            "Kysymys: 3 + 3\n",
            "Vastaus:  4\n",
            "\n",
            "\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Two-shot\n",
        "\n",
        "prompt = \"\"\"Tämä on ensimmäisen luokan matematiikan koe\n",
        "Kysymys: 3 + 4\n",
        "Vastaus: 7\n",
        "\n",
        "Kysymys: 2 + 12\n",
        "Vastaus: 14\n",
        "\n",
        "Kysymys: 1 + 2\n",
        "Vastaus: \"\"\"\n",
        "get_evaluation(prompt, \"Two\", 1, \"Vastaus: \", \"3\", 2)\n",
        "\n",
        "prompt = \"\"\"Tämä on ensimmäisen luokan matematiikan koe\n",
        "Kysymys: 5 + 2\n",
        "Vastaus: 7\n",
        "\n",
        "Kysymys: 4 + 5\n",
        "Vastaus: 9\n",
        "\n",
        "Kysymys: 3 + 3\n",
        "Vastaus: \"\"\"\n",
        "get_evaluation(prompt, \"Two\", 1, \"Vastaus: \", \"6\", 2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPTKW2dgboQJpXpHYIBCHp",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
